from typing import List, Optional, Any , Dict 
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain.prompts import PromptTemplate # Using PromptTemplate as in user's code
from pydantic import BaseModel # Import BaseModel for ChatMessage if not already defined
from langchain_core.output_parsers import StrOutputParser
class ChatMessage(BaseModel):
    role: str
    content: str


def get_response(model: Any, query: str, context: Optional[str], mode: str = "youtube", history: List[ChatMessage] = []) -> str:
    """
    Generates a response from a language model based on a query, context, mode, and chat history.

    Args:
        model: The language model instance (e.g., from Langchain).
        query: The user's current question.
        context: Relevant context for the query (e.g., transcript snippet, document text).
        mode: The mode of operation ("youtube" or "research_paper").
        history: A list of previous chat messages (role and content).

    Returns:
        The response generated by the language model.
    """
    # Build the list of messages for the prompt, including history
    messages: List[Any] = []

    # Add a system message based on the mode
    system_message_content = ""
    if mode == "research_paper":
        system_message_content = "You are an AI assistant specialized in suggesting research papers based on user queries."
    else:
        system_message_content = "You are a helpful AI assistant."

    # Add instructions about using context if available
    if context:
       
        if mode == "research_paper":
             system_message_content += "\nBased on the provided document excerpt and the chat history, answer the user's question accurately and concisely."
             system_message_content += "\nIf the answer cannot be found in the provided document excerpt, state that the information is not available in the given context."
        else:
             system_message_content += "\nBased on the provided context and chat history, answer the user's question."
             system_message_content += "\nIf the answer cannot be found in the context, state that."


    messages.append(SystemMessage(content=system_message_content))

    # Add historical messages
    for message in history:
        if message.role == "user":
            messages.append(HumanMessage(content=message.content))
        elif message.role == "assistant":
            messages.append(AIMessage(content=message.content))
        # Ignore other roles if any

    if context:
         if mode == "research_paper":
              messages.append(HumanMessage(content=f"Document Excerpt:\n{context}"))
         else:
              messages.append(HumanMessage(content=f"Context:\n{context}"))


    # Add the current user query as the final HumanMessage
    messages.append(HumanMessage(content=query))

    result = model.invoke(messages)
    result = result.content if hasattr(result, 'content') else str(result)
    result = StrOutputParser().parse(result)  # Ensure the result is a string


    return result
